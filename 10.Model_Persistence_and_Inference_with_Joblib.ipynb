{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "451bf5f3-0898-43e2-a998-b53a00fee9b2",
   "metadata": {},
   "source": [
    "# Model Persistence and Inference with Joblib in a Random Forest Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c279d29a-9c2b-43aa-9bee-0edfe2422c67",
   "metadata": {},
   "source": [
    "- Lets now summarize how to train a Random Forest model on California housing data\n",
    "- save the model and preprocessing pipeline using <b>joblib\n",
    "- and reuse the model later for inference on new data <b> ( input.csv )\n",
    "- This approach helps avoid retraining the model every time, improving performance and enabling reproducibility    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b197b7f-f5bd-444f-9db3-aa63f94a46ec",
   "metadata": {},
   "source": [
    "# Why These Steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6dabe-6b7a-4809-9d0f-3fa90597592f",
   "metadata": {},
   "source": [
    "## 1. Why Train Once and Save?\n",
    "- Training models repeatedly is time-consuming and computationally expensive.\n",
    "- Saving the model ( model.pkl ) and preprocessing pipeline ( pipeline.pkl ) ensures you can quickly load and run inference anytime in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9376e9-0a04-4d79-9018-a0907593ebaf",
   "metadata": {},
   "source": [
    "## 2. Why Use a Preprocessing Pipeline?\n",
    "- Raw data needs to be cleaned, scaled, and encoded before model training.\n",
    "- A Pipeline automates this transformation and ensures identical preprocessing during inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e84157-2db7-45db-a753-987a8230d067",
   "metadata": {},
   "source": [
    "## 3. Why Use Joblib?\n",
    "- joblib efficiently serializes large NumPy arrays (like in sklearn models).\n",
    "- Faster and more suitable than pickle for scikit-learn objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fb6f1e-1c3b-44fe-8478-3b2fd2a7dca8",
   "metadata": {},
   "source": [
    "## 4. Why the If-Else Logic?\n",
    "- The program checks if a saved model exists.\n",
    "- If not, it trains and saves the model.\n",
    "- If it does, it skips training and only runs inference, saving time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d55d654-156c-4e00-9d7f-df82e3b71a2e",
   "metadata": {},
   "source": [
    "# Full Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e26c9c6-b141-4766-bb5c-c6853488dac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ New pipeline.pkl saved successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# ---------------- LOAD DATA ----------------\n",
    "data = pd.read_csv(\"housing.csv\")\n",
    "\n",
    "TARGET = \"median_house_value\"\n",
    "X = data.drop(columns=[TARGET])\n",
    "y = data[TARGET]\n",
    "\n",
    "# ---------------- COLUMN TYPES ----------------\n",
    "\n",
    "num_features = X.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_features = X.select_dtypes(include=[\"object\", \"string\"]).columns\n",
    "\n",
    "# ---------------- PREPROCESSING ----------------\n",
    "num_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", num_pipeline, num_features),\n",
    "    (\"cat\", cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "# ---------------- FULL PIPELINE ----------------\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "# ---------------- TRAIN ----------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ---------------- SAVE PIPELINE ----------------\n",
    "# joblib.dump(pipeline, \"pipeline.pkl\")\n",
    "joblib.dump(pipeline, \"pipeline.pkl\", compress=3)\n",
    "\n",
    "print(\"✅ New pipeline.pkl saved successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e60c25-b409-4b5d-8664-1fe464bfef3c",
   "metadata": {},
   "source": [
    "##### how we have checked it \n",
    "- output.csv ki empty file banao ousme output store kro input ke output se compare kro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e58468-ed7c-4282-925f-fa706ee1ebc7",
   "metadata": {},
   "source": [
    "### Summary\n",
    "With this setup, our ML pipeline is:\n",
    "- Efficient – No retraining needed if the model exists.\n",
    "- Reproducible – Same preprocessing logic every time.\n",
    "- Production-ready – Can be deployed or reused across multiple systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0d790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
